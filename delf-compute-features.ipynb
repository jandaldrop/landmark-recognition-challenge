{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.python.platform import app\n",
    "from delf import feature_io\n",
    "\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_path='./train-highres/'\n",
    "non_landmark_train_path='./distractors/*/'\n",
    "dev_path='./dev/'\n",
    "non_landmark_dev_path='./distractors-dev/'\n",
    "test_path='./test-highres/'\n",
    "\n",
    "_DISTANCE_THRESHOLD = 0.8\n",
    "\n",
    "input_shape=(384,384)\n",
    "\n",
    "n_cat=14942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_image_files=glob.glob(train_path+'*.jpg')\n",
    "train_image_ids=[image_file.replace(\n",
    "    '.jpg','').replace(train_path,'') for image_file in train_image_files]\n",
    "train_info_full=pd.read_csv('train.csv', index_col='id')\n",
    "train_info_full.head()\n",
    "train_info=train_info_full.loc[train_image_ids]\n",
    "train_info['filename']=pd.Series(train_image_files, index=train_image_ids)\n",
    "\n",
    "train_info_correct=pd.read_csv('train_info_correct.csv', index_col='id')\n",
    "train_info=train_info[train_info['landmark_id'].isin(train_info_correct['landmark_id'])]\n",
    "\n",
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "non_landmark_image_files=glob.glob(non_landmark_train_path+'*.jp*g')\n",
    "nlm_df=pd.DataFrame({'filename':non_landmark_image_files})\n",
    "nlm_df['landmark_id']=-1\n",
    "print(len(nlm_df))\n",
    "nlm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_cat_train=train_info['landmark_id'].nunique()\n",
    "print(n_cat_train)\n",
    "if n_cat_train != n_cat:\n",
    "    warnings.warn('Warning: The training data is not compatible.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dev_image_files=glob.glob(dev_path+'*.jpg')\n",
    "dev_image_ids=[image_file.replace(\n",
    "    '.jpg','').replace(dev_path,'') for image_file in dev_image_files]\n",
    "dev_info=train_info_full.loc[dev_image_ids]\n",
    "dev_info['filename']=pd.Series(dev_image_files, index=dev_image_ids)\n",
    "#dev_info=dev_info[dev_info['landmark_id'].isin(train_info['landmark_id'])]\n",
    "dev_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "non_landmark_dev_image_files=glob.glob(non_landmark_dev_path+'*.jpg')\n",
    "nlm_dev_df=pd.DataFrame({'filename':non_landmark_dev_image_files})\n",
    "nlm_dev_df['landmark_id']=-1\n",
    "print(len(nlm_dev_df))\n",
    "nlm_dev_df.index=[str(i) for i in nlm_dev_df.index]\n",
    "nlm_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_info_full=pd.read_csv('test.csv', index_col='id')\n",
    "test_info_full.head()\n",
    "\n",
    "test_image_files=glob.glob(test_path+'*.jpg')\n",
    "test_image_ids=[image_file.replace(\n",
    "    '.jpg','').replace(test_path,'') for image_file in test_image_files]\n",
    "\n",
    "test_info=test_info_full.loc[test_image_ids]\n",
    "test_info['filename']=pd.Series(test_image_files, index=test_image_ids)\n",
    "\n",
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Landmark_id of image\", train_image_files[0], \":\", \n",
    "      train_info.loc[train_image_ids[0]]['landmark_id'])\n",
    "print(train_info[\"landmark_id\"].max())\n",
    "testimg=cv2.cvtColor(cv2.imread(np.random.choice(train_image_files)),cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(testimg)\n",
    "testimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_delf_features(info, odir, start_i=0):\n",
    "    def image_input_fn():\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "          info['filename'].values.tolist(), shuffle=False)\n",
    "        reader = tf.WholeFileReader()\n",
    "        _, value = reader.read(filename_queue)\n",
    "        image_tf_raw = tf.image.decode_jpeg(value, channels=3)\n",
    "        image_tf = tf.image.resize_images(image_tf_raw, [224, 224])\n",
    "        return tf.image.convert_image_dtype(image_tf, tf.float32)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "\n",
    "    m = hub.Module('https://tfhub.dev/google/delf/1')\n",
    "\n",
    "    # The module operates on a single image at a time, so define a placeholder to\n",
    "    # feed an arbitrary image in.\n",
    "    image_placeholder = tf.placeholder(\n",
    "        tf.float32, shape=(input_shape[0], input_shape[1], 3), name='input_image')\n",
    "\n",
    "    module_inputs = {\n",
    "        'image': image_placeholder,\n",
    "        'score_threshold': 100.0,\n",
    "        'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
    "        'max_feature_num': 1000,\n",
    "    }\n",
    "\n",
    "    module_outputs = m(module_inputs, as_dict=True)\n",
    "\n",
    "    with tf.Session() as sess:        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(start_i,len(info)):\n",
    "            fname=info.iloc[i]['filename']\n",
    "            img_id=info.index[i]\n",
    "#            print(fname)\n",
    "            try:\n",
    "                img=cv2.cvtColor(\n",
    "                    cv2.resize(cv2.imread(fname),input_shape),\n",
    "                    cv2.COLOR_BGR2RGB)/255.\n",
    "            except:\n",
    "                warnings.warn('Warning: could not read image: '+ fname +'. Use black img instead.')\n",
    "                img=np.zeros((input_shape[0], input_shape[1], 3), dtype=np.float32)\n",
    "                \n",
    "            \n",
    "            locations, descriptions = sess.run(\n",
    "                [module_outputs['locations'],  module_outputs['descriptors']],\n",
    "                feed_dict={image_placeholder: img})\n",
    "            if i % 100 ==0:\n",
    "                print(i, '/', len(info))\n",
    "                np.savetxt(odir+'last_i.txt', np.array([i]))\n",
    "            \n",
    "            np.save(odir+img_id+'_loc.npy', locations)\n",
    "            np.save(odir+img_id+'_desc.npy', descriptions)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_ref_imgs=48\n",
    "#def sample(df):\n",
    "#    return df.sample(min(n_ref_imgs,len(df)))\n",
    "#train_info_red=train_info.groupby('landmark_id', group_keys=False).apply(sample)\n",
    "#print(len(train_info_red))\n",
    "#train_info_red.to_csv('train_info_red_sample_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_info_red=pd.read_csv('train_info_red_sample_1.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_info_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_delf_features(train_info_red, 'delf-train/', start_i=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_delf_features(dev_info, 'delf-dev/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_delf_features(test_info, 'delf-test/', start_i=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_delf_features(nlm_dev_df, 'delf-nlm-dev/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
